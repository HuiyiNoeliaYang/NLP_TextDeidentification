#python main.py --epochs 1000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.8 --word_dropout_perc -1.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE>  --dataset_source "parquet" --dataset_train_split="train[:70%]" --dataset_val_split="val[:15%]" --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 3072 --label_smoothing 0.01 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

#python main.py --epochs 1000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas  --dataset_source huggingface --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

#python main.py --epochs 1000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 50 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas  --dataset_source huggingface --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --dataset_train_split "train[:1%]" --dataset_val_split "val[:1%]" --dataset_test_split "test[:1%]" --precision 16

# python main.py --epochs 1000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE>  --precision 16

# python main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE>  --precision 16

# python main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# ipython main.py --epochs 5000 --batch_size 64 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE>  --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# python main.py --epochs 5000 --batch_size 128 --max_seq_length 128 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE>  --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

#python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-4 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 5000 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE>  --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 85 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 85 --batch_size 30 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16 --debug_mode --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE>

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 200 --batch_size 35 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE>  --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-6 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16

# CUDA_VISIBLE_DEVICES=0 python main.py --epochs 100 --batch_size 35 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --checkpoint_path <SEE README TO KNOW WHAT TO PUT HERE>  --precision 16

CUDA_VISIBLE_DEVICES=0 python main.py --epochs 55 --batch_size 35 --max_seq_length 512 --word_dropout_ratio 0.0 --word_dropout_perc 0.0 --document_model_name roberta --profile_model_name tapas --local_data_path <SEE README TO KNOW WHAT TO PUT HERE> --dataset_source parquet --dataset_train_split=train[:70%] --dataset_val_split=val[:15%] --learning_rate 1e-5 --num_validations_per_epoch 1 --loss coordinate_ascent --e 768 --label_smoothing 0.00 --wandb_project_name <SEE README TO KNOW WHAT TO PUT HERE> --wandb_entity <SEE README TO KNOW WHAT TO PUT HERE> --precision 16
